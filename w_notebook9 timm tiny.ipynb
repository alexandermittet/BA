{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "start_time = time.time()\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mask_ratio =        0.75\n",
    "\n",
    "########### PATHS ############\n",
    "if os.name == 'posix': #mac\n",
    "    fine_tune_path_imgs = '/Users/alexandermittet/Library/CloudStorage/SeaDrive-almi(seafile.erda.dk) (14.03.2024 13.32)/My Libraries/BA_data/img'\n",
    "    pretrain_path_imgs = '/Users/alexandermittet/Library/CloudStorage/SeaDrive-almi(seafile.erda.dk) (14.03.2024 13.32)/My Libraries/BA_data/frames/class_0'\n",
    "    pretrain_path =     '/Users/alexandermittet/Library/CloudStorage/SeaDrive-almi(seafile.erda.dk) (14.03.2024 13.32)/My Libraries/BA_data/frames'\n",
    "    val_path_imgs =     \"/Users/alexandermittet/Library/CloudStorage/SeaDrive-almi(seafile.erda.dk) (14.03.2024 13.32)/My Libraries/BA_data/validation_frames/class_0\"\n",
    "    val_path =          \"/Users/alexandermittet/Library/CloudStorage/SeaDrive-almi(seafile.erda.dk) (14.03.2024 13.32)/My Libraries/BA_data/validation_frames\"\n",
    "    load_prev_mae_model_path =  '/Users/alexandermittet/Library/CloudStorage/SeaDrive-almi(seafile.erda.dk) (14.03.2024 13.32)/My Libraries/BA_data/models/'#mae_checkpoint_epoch-60_7198_mask-0.5 ups 0.75.pth'\n",
    "elif os.name == 'nt': #windows\n",
    "    fine_tune_path_imgs = 'C:\\\\Users\\\\alx\\\\Downloads\\\\img\\\\img'\n",
    "    pretrain_path =     r'C:\\Users\\alx\\Downloads\\BA_data\\frames'\n",
    "    val_path =          r'C:\\Users\\alx\\Downloads\\BA_data\\val_frames'\n",
    "    load_prev_mae_model_path =   f\"C:\\\\Users\\\\alx\\Downloads\\\\mdl_ckpt\\\\mae_m-{mask_ratio}\" #MAE load\n",
    "    model_used =        \"last\"\n",
    "    load_prev_fine_model_path   = f'C:\\\\Users\\\\alx\\\\Downloads\\\\mdl_ckpt\\\\mes_m-0.5\\\\mes_{model_used}.pth'\n",
    "\n",
    "\n",
    "########### HYPER PARAMETERS ############\n",
    "### MODEL SIZE\n",
    "emb_dims =          192#192 #skal ku duvuderes med num_heads som er 4 \n",
    "                    #85M params i TIMM classifiers, så den har vi smags til at 190*4 passer med 12 layers\n",
    "encoder_layers =    12#12 i timm\n",
    "architecture = \"vit_base_patch16_224\" #tiny eller small\n",
    "\n",
    "### Pretraining\n",
    "training =          False #Pre-training MAE\n",
    "num_epochs =        33\n",
    "dim =               224\n",
    "\n",
    "\n",
    "### Global hyper params\n",
    "custom_opt =            \"prodigy\" #bliver også brugt til fine tuning\n",
    "learn_rate =            0.001\n",
    "MAE_batch_size =        32\n",
    "mes_batch_size =        32\n",
    "load_prev_model =       False #MAE load\n",
    "mae_to_load =           'mae_last_bs512.pth'\n",
    "mae_load_path = os.path.join(load_prev_mae_model_path, mae_to_load)\n",
    "\n",
    "### Fine-tuning\n",
    "three_shot =        True # 3-shot mes runs w/plots\n",
    "load_fine_tuned =   False or three_shot #meS vi bliver nødt til, for at evaluere MES best.pth (og ikke last, som vi stadig ligger i memory)\n",
    "fine_tuning =       False or three_shot #MES training\n",
    "fine_tune_eval =    False or three_shot\n",
    "num_fine_epochs =   5 #overfitter efter færre faktisk, men vi gemmer også best\n",
    "\n",
    "###SSIM Score #approx x mins\n",
    "plot_ssim        =       False\n",
    "### Plot best and worst loss imgs\n",
    "plot_bwl =          False\n",
    "\n",
    "### T-sne feature plotting # approx 5 mins\n",
    "tsne_plotting =     False\n",
    "# tsne_target =       \"all mes\" #mes: \"all mes\", \"mes1to3\" #MAE:\"validation images\" \"training images\"\n",
    "plot_single_image = False\n",
    "plot_16_images =    False or load_prev_model #might aswell så vi kan se hvor god vi loader\n",
    "\n",
    "### PCA #approx 4 mins\n",
    "plot_pca   =        False\n",
    "\n",
    "### Misc\n",
    "get_num_params =    False\n",
    "break_after_num_steps = -1\n",
    "use_class4 =        False\n",
    "\n",
    "run_name =          f\"decontam-data_opt_{custom_opt}_max-e-{num_epochs}_m-{mask_ratio}_fine-e-{num_fine_epochs}_MAE-mes-bs-{MAE_batch_size}-{mes_batch_size}\" #hyperparam string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alx\\miniconda3.2\\envs\\BA\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "#import torch.optim as optim #bruger prodigy\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from prodigyopt import Prodigy\n",
    "from torch.optim import AdamW\n",
    "import lightning as L\n",
    "# import wandb\n",
    "\n",
    "from einops import repeat, rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from timm.models.layers import trunc_normal_\n",
    "from timm.models.vision_transformer import Block\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((dim, dim)), # Resize the image\n",
    "    transforms.ToTensor(), # Convert the image to a PyTorch tensor\n",
    "])\n",
    "\n",
    "#dataset = CustomFramesDataset(root_dir=frames_path, transform=transform)\n",
    "dataset = ImageFolder(\n",
    "        pretrain_path,\n",
    "        transform=transform,\n",
    "    )\n",
    "\n",
    "val_dataset = ImageFolder(\n",
    "        val_path,\n",
    "        transform=transform,\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model architecture + masking fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ViT Model + functions\n",
    "class MAE_Encoder(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 image_size=dim,\n",
    "                 patch_size=16,\n",
    "                 emb_dim=emb_dims,\n",
    "                 num_layer=encoder_layers,\n",
    "                 num_head=4,\n",
    "                 mask_ratio=mask_ratio,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.cls_token = torch.nn.Parameter(torch.zeros(1, 1, emb_dim))\n",
    "        self.pos_embedding = torch.nn.Parameter(torch.zeros((image_size // patch_size) ** 2, 1, emb_dim))\n",
    "        self.shuffle = PatchShuffle(mask_ratio)\n",
    "\n",
    "        self.patchify = torch.nn.Conv2d(3, emb_dim, patch_size, patch_size)\n",
    "\n",
    "        self.transformer = torch.nn.Sequential(*[Block(emb_dim, num_head) for _ in range(num_layer)])\n",
    "\n",
    "        self.layer_norm = torch.nn.LayerNorm(emb_dim)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        trunc_normal_(self.cls_token, std=.02)\n",
    "        trunc_normal_(self.pos_embedding, std=.02)\n",
    "\n",
    "    def forward(self, img):\n",
    "        patches = self.patchify(img)\n",
    "        patches = rearrange(patches, 'b c h w -> (h w) b c')\n",
    "        \n",
    "        # Calculate the number of patches\n",
    "        num_patches = patches.shape[0]\n",
    "        \n",
    "\n",
    "        \n",
    "        patches = patches + self.pos_embedding\n",
    "\n",
    "        patches, forward_indexes, backward_indexes = self.shuffle(patches)\n",
    "\n",
    "        patches = torch.cat([self.cls_token.expand(-1, patches.shape[1], -1), patches], dim=0)\n",
    "        patches = rearrange(patches, 't b c -> b t c')\n",
    "        features = self.layer_norm(self.transformer(patches))\n",
    "        features = rearrange(features, 'b t c -> t b c')\n",
    "\n",
    "        return features, backward_indexes\n",
    "\n",
    "class MAE_Decoder(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 image_size=dim,\n",
    "                 patch_size=16,\n",
    "                 emb_dim=192,\n",
    "                 num_layer=4,\n",
    "                 num_head=3,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.mask_token = torch.nn.Parameter(torch.zeros(1, 1, emb_dim))\n",
    "        self.pos_embedding = torch.nn.Parameter(torch.zeros((image_size // patch_size) ** 2 + 1, 1, emb_dim))\n",
    "\n",
    "        self.transformer = torch.nn.Sequential(*[Block(emb_dim, num_head) for _ in range(num_layer)])\n",
    "\n",
    "        self.head = torch.nn.Linear(emb_dim, 3 * patch_size ** 2)\n",
    "        self.patch2img = Rearrange('(h w) b (c p1 p2) -> b c (h p1) (w p2)', p1=patch_size, p2=patch_size, h=image_size//patch_size)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        trunc_normal_(self.mask_token, std=.02)\n",
    "        trunc_normal_(self.pos_embedding, std=.02)\n",
    "\n",
    "    def forward(self, features, backward_indexes):\n",
    "        T = features.shape[0]\n",
    "        backward_indexes = torch.cat([torch.zeros(1, backward_indexes.shape[1]).to(backward_indexes), backward_indexes + 1], dim=0)\n",
    "        features = torch.cat([features, self.mask_token.expand(backward_indexes.shape[0] - features.shape[0], features.shape[1], -1)], dim=0)\n",
    "        features = take_indexes(features, backward_indexes)\n",
    "        features = features + self.pos_embedding\n",
    "\n",
    "        features = rearrange(features, 't b c -> b t c')\n",
    "        features = self.transformer(features)\n",
    "        features = rearrange(features, 'b t c -> t b c')\n",
    "        features = features[1:] # remove global feature\n",
    "\n",
    "        patches = self.head(features)\n",
    "        mask = torch.zeros_like(patches)\n",
    "        mask[T-1:] = 1\n",
    "        mask = take_indexes(mask, backward_indexes[1:] - 1)\n",
    "        img = self.patch2img(patches)\n",
    "        mask = self.patch2img(mask)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "class MAE_ViT(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 image_size=dim,\n",
    "                 patch_size=16,\n",
    "                 emb_dim=emb_dims,#192,\n",
    "                 encoder_layer=encoder_layers,#12,\n",
    "                 encoder_head=4,\n",
    "                 decoder_layer=4,\n",
    "                 decoder_head=4,\n",
    "                 mask_ratio=mask_ratio,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = MAE_Encoder(image_size, patch_size, emb_dim, encoder_layer, encoder_head, mask_ratio)\n",
    "        self.decoder = MAE_Decoder(image_size, patch_size, emb_dim, decoder_layer, decoder_head)\n",
    "\n",
    "    def forward(self, img):\n",
    "        features, backward_indexes = self.encoder(img)\n",
    "        predicted_img, mask = self.decoder(features,  backward_indexes)\n",
    "        return predicted_img, mask\n",
    "\n",
    "class ViT_Classifier(torch.nn.Module):\n",
    "    def __init__(self, encoder : MAE_Encoder, num_classes=4) -> None:\n",
    "        super().__init__()\n",
    "        self.cls_token = encoder.cls_token\n",
    "        self.pos_embedding = encoder.pos_embedding\n",
    "        self.patchify = encoder.patchify\n",
    "        self.transformer = encoder.transformer\n",
    "        self.layer_norm = encoder.layer_norm\n",
    "        self.head = torch.nn.Linear(self.pos_embedding.shape[-1], num_classes)\n",
    "\n",
    "    def forward(self, img):\n",
    "        patches = self.patchify(img)\n",
    "        patches = rearrange(patches, 'b c h w -> (h w) b c')\n",
    "        patches = patches + self.pos_embedding\n",
    "        patches = torch.cat([self.cls_token.expand(-1, patches.shape[1], -1), patches], dim=0)\n",
    "        patches = rearrange(patches, 't b c -> b t c')\n",
    "        features = self.layer_norm(self.transformer(patches))\n",
    "        features = rearrange(features, 'b t c -> t b c')\n",
    "        logits = self.head(features[0])\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class PatchShuffle(torch.nn.Module):\n",
    "    def __init__(self, ratio) -> None:\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def forward(self, patches : torch.Tensor):\n",
    "        T, B, C = patches.shape\n",
    "        remain_T = int(T * (1 - self.ratio))\n",
    "\n",
    "        indexes = [random_indexes(T) for _ in range(B)]\n",
    "        forward_indexes = torch.as_tensor(np.stack([i[0] for i in indexes], axis=-1), dtype=torch.long).to(patches.device)\n",
    "        backward_indexes = torch.as_tensor(np.stack([i[1] for i in indexes], axis=-1), dtype=torch.long).to(patches.device)\n",
    "\n",
    "        patches = take_indexes(patches, forward_indexes)\n",
    "        patches = patches[:remain_T]\n",
    "\n",
    "        return patches, forward_indexes, backward_indexes\n",
    "    \n",
    "def random_indexes(size : int):\n",
    "    forward_indexes = np.arange(size)\n",
    "    np.random.shuffle(forward_indexes)\n",
    "    backward_indexes = np.argsort(forward_indexes)\n",
    "    return forward_indexes, backward_indexes\n",
    "\n",
    "def take_indexes(sequences, indexes):\n",
    "    return torch.gather(sequences, 0, repeat(indexes, 't b -> t b c', c=sequences.shape[-1]))\n",
    "\n",
    "def mask_image(image, mask_size):\n",
    "    mask = torch.ones_like(image)\n",
    "    mask[:, :mask_size, :mask_size] = 0\n",
    "    return image * mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load MAE model if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    import torch\n",
    "    import os\n",
    "\n",
    "    if os.path.exists(mae_load_path):\n",
    "        # Load the checkpoint\n",
    "        checkpoint = torch.load(mae_load_path)\n",
    "        \n",
    "        # Load the model state dict\n",
    "        model = MAE_ViT().to(device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # Load the optimizer state dict\n",
    "        if custom_opt == \"prodigy\":\n",
    "            optimizer = Prodigy(model.parameters())\n",
    "        elif custom_opt == \"adamW\":\n",
    "            optimizer = AdamW(model.parameters(), lr=learn_rate)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        # Load the loss\n",
    "        loss = checkpoint['loss']\n",
    "        \n",
    "        print(f\"Model loaded with loss: {loss}\")\n",
    "    else:\n",
    "        \n",
    "        print(\"Model checkpoint not found.\")\n",
    "    return model, optimizer, loss\n",
    "\n",
    "if load_prev_model:\n",
    "    model, optimizer, loss = load_model()\n",
    "else:\n",
    "    model = MAE_ViT().to(device)\n",
    "    if custom_opt == \"adamW\":\n",
    "        learning_rate = learn_rate # Example learning rate\n",
    "        optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    elif custom_opt == \"prodigy\":\n",
    "        optimizer = Prodigy(model.parameters())\n",
    "    #loss er custom mse loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Num_params in MAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_num_params or plot_16_images:\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total number of parameters: {total_params:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsampler import ImbalancedDatasetSampler\n",
    "dataloader = DataLoader(dataset, batch_size=MAE_batch_size, sampler=ImbalancedDatasetSampler(dataset)) #sampler=cycle_sampler\n",
    "val_loader = DataLoader(val_dataset, batch_size=MAE_batch_size, sampler=ImbalancedDatasetSampler(val_dataset))\n",
    "   \n",
    "if training:    #Tensorboard writer\n",
    "    \n",
    "    import random\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    # Format the datetime string to exclude the year\n",
    "    formatted_datetime = now.strftime(\"%m-%d_%H-%M\")\n",
    "    # Use the formatted datetime in the path\n",
    "    writer = SummaryWriter(os.path.join(\"logs\", \"mae\", f\"{formatted_datetime}_{run_name}\"))\n",
    "\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    step_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        pbar = tqdm(iter(dataloader))\n",
    "        for img, label in pbar:\n",
    "            step_count += 1\n",
    "            img = img.to(device)\n",
    "            predicted_img, mask = model(img)\n",
    "            loss = (\n",
    "                    torch.mean((predicted_img - img) ** 2 * mask) / mask_ratio\n",
    "                )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            pbar.set_postfix({'step loss': loss.item()}, refresh=False)\n",
    "            writer.add_scalar(\"mae/step_train_loss\", loss.item(), global_step=step_count)\n",
    "            # wandb.log({\"Train Loss step\": loss})\n",
    "\n",
    "            if break_after_num_steps > 0: #set to -1 to disable early breaking\n",
    "                if step_count >= break_after_num_steps: #Save and quit\n",
    "                    # torch.save({\n",
    "                    #             'model_state_dict': model.state_dict(),\n",
    "                    #             'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    #             'loss': loss.item(),\n",
    "                    #             }, './models/mae_checkpoint_break.pth')\n",
    "                    break\n",
    "        \n",
    "        #For every epoch:\n",
    "        avg_loss = sum(losses) / len(losses)\n",
    "        writer.add_scalar(\"mae/epoch_train_loss\", avg_loss, global_step=step_count)\n",
    "        print(f\"####TRAIN#### epoch {epoch}/{num_epochs}, avg train loss: {avg_loss:.4f}\")\n",
    "        # wandb.log({\"Train Loss epoch avg\": avg_loss})\n",
    "\n",
    "        \"\"\" visualize the first 16 predicted images on val dataset\"\"\"\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_bar = tqdm(iter(val_loader))\n",
    "        with torch.no_grad():\n",
    "            for img, label in val_bar:\n",
    "                img = img.to(device)\n",
    "                predicted_img, mask = model(img)\n",
    "                val_loss = (\n",
    "                        torch.mean((predicted_img - img) ** 2 * mask) / mask_ratio\n",
    "                    )\n",
    "                val_losses.append(val_loss.item())\n",
    "                #break #vi vil gerne køre alt validatio igennem\n",
    "            \n",
    "            avg_val_loss = torch.mean(torch.tensor(val_losses))\n",
    "            writer.add_scalar(\"mae/epoch_val_loss\", avg_val_loss.item(), global_step=step_count)\n",
    "\n",
    "            \n",
    "\n",
    "        ### Saving\n",
    "        if val_loss < best_val_loss:\n",
    "            improved = True\n",
    "            # Update the best loss\n",
    "            best_val_loss = val_loss\n",
    "            \n",
    "            # Construct the filename with the current loss included\n",
    "            filename = f\"mae_best.pth\"\n",
    "        else:\n",
    "            improved = False\n",
    "            filename = \"mae_last.pth\"\n",
    "        # Construct the full path using os.path.join\n",
    "        base_path = f\"C:\\\\Users\\\\alx\\\\Downloads\\\\mdl_ckpt\\\\mae_m-{mask_ratio}\"\n",
    "        full_path = os.path.join(base_path, filename)\n",
    "        shortened_path = os.path.join(f\"mdl_ckpt\\\\mae_m-{mask_ratio}\", filename)\n",
    "        \n",
    "        # Save the model\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "        }, full_path)\n",
    "        if improved:\n",
    "            print(f\"###IMPROVED VAL#### Save w/avg loss {avg_loss:.4f} at {shortened_path}\")\n",
    "        \n",
    "        improved = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval 16 random imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import random\n",
    "# from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "# def plot_16_images_():\n",
    "    \n",
    "#     num_samples = 16\n",
    "#     indices = random.sample(range(len(val_dataset)), num_samples)\n",
    "#     val_samples = [val_dataset[i][0] for i in indices]\n",
    "#     val_img = torch.stack(val_samples)\n",
    "#     #val_img = torch.stack([val_dataset[i][0] for i in range(21)])\n",
    "    \n",
    "\n",
    "#     val_img = val_img.to(device)\n",
    "#     predicted_val_img, mask = model(val_img)\n",
    "#     predicted_val_img = predicted_val_img * mask + val_img * (1 - mask)\n",
    "\n",
    "#     img = torch.cat([val_img * (1 - mask), predicted_val_img, val_img], dim=0)\n",
    "#     img = rearrange(img, \"(v h1 w1) c h w -> (h1 h) (w1 v w) c\", w1=2, v=3)\n",
    "#     img_np = img.cpu().detach().numpy()\n",
    "#     # min_val, max_val = np.min(img_np), np.max(img_np)\n",
    "#     # range_val = max_val - min_val\n",
    "\n",
    "#     # Normalize the data\n",
    "#     # normalized_img_np = (img_np - min_val) / range_val\n",
    "\n",
    "#     plt.figure(figsize=(6, 8))\n",
    "#     plt.axis('off')\n",
    "#     plt.title(f'MAE: 16 random val images \\n MAE pretrained for: {num_epochs}eps, masking: {mask_ratio} \\n MAE model has {total_params:,.0f} num params')\n",
    "#     # plt.imshow(normalized_img_np)\n",
    "#     plt.imshow(img_np) #imgs look grey when normalized\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f\"plots/mae_image_16x_m-{mask_ratio}_params-{total_params:,.0f}.png\")\n",
    "#     plt.show()\n",
    "# if plot_16_images:\n",
    "#     plot_16_images_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worst/best images (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_bwl:\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from torch.utils.data import DataLoader\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    # Assuming 'model' is your trained model and 'val_dataset' is your validation dataset\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "\n",
    "    losses = []\n",
    "    indices = []\n",
    "    wbl_loader = DataLoader(val_dataset, batch_size=1)\n",
    "    wbl_bar = tqdm(iter(wbl_loader))\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculation to save memory\n",
    "        for i, (img, label) in enumerate(wbl_bar):\n",
    "            img = img.to(device) # maybe its faster to use cpu for single image losses?\n",
    "            predicted_img, mask = model(img) # Pass the image through the model\n",
    "            loss = (torch.mean((predicted_img - img) ** 2 * mask) / mask_ratio)\n",
    "            losses.append(loss.item()) # Store the loss\n",
    "            indices.append(i) # Store the index of the image in the dataset\n",
    "\n",
    "    # Sort the losses and select the top 10 and bottom 10\n",
    "    sorted_indices = np.argsort(losses)\n",
    "    top_10_indices = sorted_indices[-10:]\n",
    "    bottom_10_indices = sorted_indices[:10]\n",
    "\n",
    "    # Now, you can index into the dataset to get the images\n",
    "    top_10_images = [val_dataset[i][0] for i in top_10_indices]\n",
    "    bottom_10_images = [val_dataset[i][0] for i in bottom_10_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_bwl:\n",
    "    x, y = 10, 5.5\n",
    "    # Plotting the top 10 images with their losses\n",
    "    plt.figure(figsize=(x, y))\n",
    "    for i, img in enumerate(top_10_images):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(img.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
    "        plt.title(f\"Loss: {losses[top_10_indices[i]]:.4f}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"10 highest loss images\", fontsize=16)\n",
    "    plt.savefig(f\"plots/worst-best/mae_10_bwl_highest.png\")\n",
    "\n",
    "    # Plotting the bottom 10 images with their losses\n",
    "\n",
    "    plt.figure(figsize=(x, y))\n",
    "    for i, img in enumerate(bottom_10_images):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(img.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
    "        plt.title(f\"Loss: {losses[bottom_10_indices[i]]:.4f}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"10 lowest loss images\", fontsize=16)\n",
    "    plt.savefig(f\"plots/worst-best/mae_10_bwl_lowest.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quant ssim scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "import random\n",
    "\n",
    "if plot_ssim:\n",
    "    def plot_ssim_scores(num_samples):\n",
    "        # Initialize SSIM metric with specified parameters\n",
    "        ssim = StructuralSimilarityIndexMeasure(\n",
    "            gaussian_kernel=True,\n",
    "            sigma=1.5,\n",
    "            kernel_size=11,\n",
    "            reduction='none', # Get individual scores for each image\n",
    "            data_range=1.0, # Assuming images are normalized between 0 and 1\n",
    "            k1=0.01,\n",
    "            k2=0.03,\n",
    "            return_full_image=False,\n",
    "            return_contrast_sensitivity=False\n",
    "        ).to(device)\n",
    "        \n",
    "        # Sample validation images\n",
    "        indices = random.sample(range(len(val_dataset)), num_samples)\n",
    "        val_samples = [val_dataset[i][0] for i in indices]\n",
    "        val_img = torch.stack(val_samples)\n",
    "        \n",
    "        # Move images to the device\n",
    "        val_img = val_img.to(device)\n",
    "        \n",
    "        # Generate predictions\n",
    "        predicted_val_img, mask = model(val_img)\n",
    "        predicted_val_img = predicted_val_img * mask + val_img * (1 - mask)\n",
    "        \n",
    "        # Calculate SSIM scores for each image\n",
    "        ssim_scores = []\n",
    "        for original, predicted in zip(val_img, predicted_val_img):\n",
    "            score = ssim(predicted.unsqueeze(0), original.unsqueeze(0))\n",
    "            ssim_scores.append(score.item())\n",
    "        \n",
    "        # Convert list of scores to a NumPy array for plotting\n",
    "        ssim_scores_np = np.array(ssim_scores)\n",
    "        mean_sc = np.mean(ssim_scores_np)\n",
    "        # Plot SSIM scores\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(ssim_scores_np, marker='o', linestyle='')\n",
    "        plt.title(f'SSIM Scores for Validation Images (Mean = {mean_sc})')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xlabel('Image Index')\n",
    "        plt.ylabel('SSIM Score')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"plots/mae_ssim_scores_val.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        return ssim_scores_np\n",
    "\n",
    "if plot_ssim:\n",
    "    scores = plot_ssim_scores(num_samples=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del val_img, predicted_val_img, mask, ssim_scores, ssim_scores_np\n",
    "# #free up leaky memory\n",
    "# plt.close(\"all\")  # Close all figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quali random ssim w img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "from einops import rearrange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "from einops import rearrange\n",
    "\n",
    "def plot_single_image_ssim(index=None):\n",
    "    # Select a single image from the dataset\n",
    "    #pick a random index from 0 to len(val_dataset)\n",
    "    if index is None:\n",
    "        index = random.randint(0, len(val_dataset) - 1)\n",
    "    val_img = val_dataset[index][0].unsqueeze(0).to(device)\n",
    "    \n",
    "    # Make a prediction\n",
    "    predicted_val_img, mask = model(val_img)\n",
    "    predicted_val_img = predicted_val_img * mask + val_img * (1 - mask)\n",
    "    \n",
    "    # Prepare the images for plotting\n",
    "    # Concatenate the masked input, prediction, and ground truth\n",
    "    img = torch.cat([val_img * (1 - mask), predicted_val_img, val_img], dim=0)\n",
    "    # Adjust the rearrange pattern to match the new order\n",
    "    img = rearrange(img, \"v c h w -> (v h) w c\", v=3)\n",
    "    img_np = img.cpu().detach().numpy()\n",
    "    # min_val, max_val = np.min(img_np), np.max(img_np)\n",
    "    # range_val = max_val - min_val\n",
    "    # normalized_img_np = (img_np - min_val) / range_val\n",
    "    \n",
    "    # Calculate SSIM score\n",
    "    ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "    score = ssim(val_img, predicted_val_img).item()\n",
    "    \n",
    "    # Plot the images\n",
    "    plt.figure(figsize=(2, 6))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_np) # we dont need to normalize\n",
    "    \n",
    "    # Add SSIM score below the plot\n",
    "    plt.text(0.5, -0.1, f'SSIM: {score:.4f}', fontsize=12, ha='center', transform=plt.gca().transAxes)\n",
    "    plt.tight_layout\n",
    "    plt.savefig(f\"plots/worst-best/single_image_SSIM_{score:.4f}.png\")\n",
    "    plt.show()\n",
    "\n",
    "if plot_ssim:\n",
    "    model = model.to(device)\n",
    "    plot_single_image_ssim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best and worst SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_ssim:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Assuming scores is already defined and contains your SSIM scores\n",
    "    # Find the indices that would sort the scores\n",
    "    sorted_indices = np.argsort(scores)\n",
    "\n",
    "    # Select the indices of the best and worst images\n",
    "    best_indices = sorted_indices[-5:] # Adjust the number as needed\n",
    "    worst_indices = sorted_indices[:5] # Adjust the number as needed\n",
    "\n",
    "    # Select the best and worst images\n",
    "    best_images = [val_dataset[i][0] for i in best_indices]\n",
    "    worst_images = [val_dataset[i][0] for i in worst_indices]\n",
    "\n",
    "    # Get the SSIM scores for the best and worst images\n",
    "    best_scores = [scores[i] for i in best_indices]\n",
    "    worst_scores = [scores[i] for i in worst_indices]\n",
    "\n",
    "    # Plot the best images with their SSIM scores\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    for i, (img, score) in enumerate(zip(best_images, best_scores)):\n",
    "        plt.subplot(1, len(best_images), i+1)\n",
    "        plt.imshow(img.permute(1, 2, 0).cpu().numpy()) # Adjust the permute order based on your image format\n",
    "        plt.title(f'SSIM: {score:.3f}')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('5 Best Images by SSIM Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/5_best_images_SSIM.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Plot the worst images with their SSIM scores\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    for i, (img, score) in enumerate(zip(worst_images, worst_scores)):\n",
    "        plt.subplot(1, len(worst_images), i+1)\n",
    "        plt.imshow(img.permute(1, 2, 0).cpu().numpy()) # Adjust the permute order based on your image format\n",
    "        plt.title(f'SSIM: {score:.3f}')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('5 Worst Images by SSIM Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/5_worst_images_SSIM.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-SNE feature embeddings (clustering our latent space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just tsne plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tsne_plotting:\n",
    "    from torchvision import transforms\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import torch\n",
    "    from tqdm import tqdm \n",
    "    from sklearn.manifold import TSNE\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def tsne_embeddings(input_paths: list, model) -> np.ndarray:\n",
    "        encoder = model.encoder\n",
    "        encoder.eval() # Set the model to evaluation mode\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)), # Adjust size as needed\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        # Extract features\n",
    "        features = []\n",
    "        for path in tqdm(input_paths, desc=\"Processing images\"): # Wrap image_paths with tqdm\n",
    "            img = Image.open(path)\n",
    "            img = transform(img).unsqueeze(0) # Add batch dimension\n",
    "            with torch.no_grad():\n",
    "                _, feature = encoder(img)\n",
    "            features.append(feature.squeeze().numpy())\n",
    "        # np.vstack enables parallel processing\n",
    "        features = np.vstack(features)\n",
    "\n",
    "        # Apply t-SNE\n",
    "        tsne = TSNE(n_components=2, random_state=42, n_jobs=-1, verbose=1) #12 it/s ved n_jobs=None\n",
    "        embeddings = tsne.fit_transform(features)\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "    # if tsne_target == \"training images\":\n",
    "    #     embedding = tsne_embeddings(pretrain_path_imgs)\n",
    "    # elif tsne_target == \"validation images\":\n",
    "    #     embedding = tsne_embeddings(val_path_imgs)\n",
    "    # §if tsne_target == \"all mes\":\n",
    "    if True:\n",
    "        df = pd.read_csv('img_labels_ALL.csv')\n",
    "        image_paths = [os.path.join(fine_tune_path_imgs, img_name) for img_name in df['img']]\n",
    "        #####TAKES TIME#######\n",
    "        embeddings = tsne_embeddings(image_paths, model)\n",
    "    else:\n",
    "        print(\"Invalid target for t-SNE plotting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT\n",
    "if tsne_plotting:\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=embeddings[:, 0], y=embeddings[:, 1], hue=df['score'], palette='viridis')\n",
    "    plt.title('MES images t-SNE embeddings from MAE')\n",
    "    plt.legend(title='MES-score', title_fontsize='13')\n",
    "    plt.savefig(f\"plots/tsne/mes/t-sne_all.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tsne with images on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(input_path, which_type):\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "    def getImage(path, zoom=.025):\n",
    "        return OffsetImage(plt.imread(path), zoom=zoom)\n",
    "\n",
    "    # Specify the directory containing the images\n",
    "    image_directory = input_path\n",
    "\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(image_directory)\n",
    "\n",
    "    # Filter out the image files (assuming .jpg and .png extensions)\n",
    "    image_files = [os.path.join(image_directory, f) for f in files if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Assuming 'embedding' is defined elsewhere in your code\n",
    "    for x0, y0, path in zip(embedding[:, 0], embedding[:, 1], image_files):\n",
    "        ab = AnnotationBbox(getImage(path), (x0, y0), frameon=False)\n",
    "        ax.add_artist(ab)\n",
    "\n",
    "    # Set the limits of the plot to ensure all images are visible\n",
    "    # You might need to adjust these limits based on the range of your embedding coordinates\n",
    "    ax.set_xlim(embedding[:, 0].min(), embedding[:, 0].max())\n",
    "    ax.set_ylim(embedding[:, 1].min(), embedding[:, 1].max())\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"%y%m%d_%H%M\")\n",
    "    \n",
    "    title = f\" T-sne plot of feature embeddings of {which_type} images. Mask Ratio: {mask_ratio}\"\n",
    "\n",
    "    # Set the title of the plot\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Save the figure with the datetime stamp in the filename\n",
    "    plt.savefig(f'./plots/tsne_time-{timestamp}_mask-{mask_ratio}_type-{which_type}.png')\n",
    "    plt.show()\n",
    "\n",
    "if tsne_plotting:\n",
    "    if tsne_target == \"training images\":\n",
    "        plot_tsne(pretrain_path_imgs, 'training')\n",
    "    elif tsne_target == \"validation images\":\n",
    "        plot_tsne(val_path_imgs,'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA feature embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def pca_embeddings(input_paths: list, model) -> np.ndarray:\n",
    "    encoder = model.encoder\n",
    "    encoder = encoder.to(device)\n",
    "    encoder.eval() # Set the model to evaluation mode\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), # Adjust size as needed\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Extract features\n",
    "    features = []\n",
    "    for path in tqdm(input_paths, desc=\"Processing images\"): # Wrap image_paths with tqdm\n",
    "        img = Image.open(path)\n",
    "        img = transform(img).unsqueeze(0) # Add batch dimension\n",
    "        img = img.to(device)\n",
    "        with torch.no_grad():\n",
    "            feature, backwards_index = encoder(img) #MAE ENC: return features, backward_indexes\n",
    "        features.append(feature.squeeze().cpu().numpy())\n",
    "    # np.vstack enables parallel processing\n",
    "    features = np.vstack(features)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    pca = PCA().fit(scaled_features)    \n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "    cumulative_explained_variance = np.cumsum(explained_variance)\n",
    "\n",
    "\n",
    "    return explained_variance, cumulative_explained_variance\n",
    "\n",
    "if plot_pca:\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('img_labels_ALL.csv')\n",
    "    image_paths = [os.path.join(fine_tune_path_imgs, img_name) for img_name in df['img']]\n",
    "    #####TAKES TIME#######\n",
    "    explained_variance, cumulative_explained_variance = pca_embeddings(image_paths, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_pca:\n",
    "    num_components_for_80_variance = np.argmax(cumulative_explained_variance >= 0.80) + 1\n",
    "    print(f\"Number of components needed for 80% variance: {num_components_for_80_variance}\")\n",
    "\n",
    "    num_components_for_95_variance = np.argmax(cumulative_explained_variance >= 0.95) + 1\n",
    "    print(f\"Number of components needed for 95% variance: {num_components_for_95_variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_pca:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(range(1, len(explained_variance) + 1), cumulative_explained_variance, marker='.', linestyle='--')\n",
    "    # plt.axvline(x=138, color='red', linestyle='--')\n",
    "    # plt.axvline(x=179, color='red', linestyle='--')\n",
    "    plt.axhline(y=0.8, color='red', linestyle='--')\n",
    "    plt.axhline(y=0.95, color='red', linestyle='--')\n",
    "    plt.xlim(0, emb_dims)\n",
    "    plt.plot([num_components_for_80_variance, num_components_for_95_variance], [0.8, 0.95], 'ro')\n",
    "    plt.xlabel('Number of Components (Embedded Dimensions)')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.title('PCA - Explained Variance by Number of Embedded Dimensions')\n",
    "    plt.legend([\n",
    "        'Cumulative Explained Variance',\n",
    "        f'80% Explained Variance ({num_components_for_80_variance} components)',\n",
    "        f'95% Explained Variance ({num_components_for_95_variance} components)'\n",
    "    ], loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/pca_num_emb-dims_m-{mask_ratio}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune model MES score 1x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "import timm\n",
    "# encoder = model.encoder\n",
    "# classifier = ViT_Classifier(encoder, num_classes=4)\n",
    "# classifier = timm.create_model(\n",
    "#             architecture, pretrained=True, num_classes=4\n",
    "#         )  # Get model architecture\n",
    "# classifier.to(device)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# #initialize new optimizers that arent biased from MAE training\n",
    "# if custom_opt == \"prodigy\":\n",
    "#     optimizer = Prodigy(classifier.parameters())\n",
    "# elif custom_opt == \"adamW\":\n",
    "#     optimizer = AdamW(classifier.parameters(), lr=learn_rate)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx, 0]\n",
    "        img_path = f'{fine_tune_path_imgs}/{img_name}' ##### MAN KAN ÆNDRE PATH HER ift /class_0\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = torch.tensor(self.df.iloc[idx, 2], dtype=torch.long)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    def get_labels(self):\n",
    "        label = torch.tensor(self.df.iloc[:, 2].tolist(), dtype=torch.long)\n",
    "        return label\n",
    "    \n",
    "def init_dataloaders():\n",
    "        #DATA LABELS\n",
    "    df = pd.read_csv('img_labels_ALL.csv')\n",
    "\n",
    "    # Remove class 4 (images lablelled as bad examples)\n",
    "    if use_class4 == False:\n",
    "        df = df[df['score'] != 4.0]\n",
    "    #df.head() #Sanity check\n",
    "\n",
    "    # Only use images that exist in the directory\n",
    "    image_folder = fine_tune_path_imgs\n",
    "    image_exists = df['img'].apply(lambda x: os.path.isfile(os.path.join(image_folder, x))) \n",
    "    filtered_df = df[image_exists]\n",
    "    print(f\"Original DataFrame size: {len(df)}, Filtered DataFrame size: {len(filtered_df)}\") #Sanity check\n",
    "    df = filtered_df\n",
    "\n",
    "    # Stratify/balance classes across splits\n",
    "    labels = df['score'].values\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=labels)\n",
    "    train_labels = train_df['score'].values\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_labels)\n",
    "\n",
    "    # Create data loaders for training and validation sets\n",
    "    test_data = CustomDataset(test_df, transform)\n",
    "    train_data = CustomDataset(train_df, transform)\n",
    "    val_data = CustomDataset(val_df, transform)\n",
    "\n",
    "    #More workers for GPU/lambda\n",
    "    if torch.cuda.is_available():\n",
    "        num_workers_local = 0\n",
    "        test_loader = DataLoader(test_data, batch_size=mes_batch_size, num_workers=num_workers_local)\n",
    "        train_loader = DataLoader(train_data, batch_size=mes_batch_size, sampler=ImbalancedDatasetSampler(train_data))#, num_workers=num_workers_local)\n",
    "        val_loader = DataLoader(val_data, batch_size=mes_batch_size, num_workers=num_workers_local)\n",
    "    else:\n",
    "        test_loader = DataLoader(test_data, batch_size=mes_batch_size)\n",
    "        train_loader = DataLoader(train_data, batch_size=mes_batch_size, sampler=ImbalancedDatasetSampler(train_data))\n",
    "        val_loader = DataLoader(val_data, batch_size=mes_batch_size)\n",
    "    return train_loader, val_loader, test_loader, test_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def single_mes_run(iteration=None):\n",
    "    if fine_tuning == True or three_shot:\n",
    "        train_loader, val_loader, test_loader, test_data = init_dataloaders()\n",
    "        classifier = timm.create_model(\n",
    "            architecture, pretrained=True, num_classes=4\n",
    "        )  # Get model architecture\n",
    "        classifier.to(device)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        #initialize new optimizers that arent biased from MAE training\n",
    "        if custom_opt == \"prodigy\":\n",
    "            optimizer = Prodigy(classifier.parameters())\n",
    "        elif custom_opt == \"adamW\":\n",
    "            optimizer = AdamW(classifier.parameters(), lr=learn_rate)\n",
    "        from datetime import datetime\n",
    "        now = datetime.now()\n",
    "\n",
    "        # Format the datetime string to exclude the year\n",
    "        formatted_datetime = now.strftime(\"%m-%d_%H-%M\")\n",
    "        # Use the formatted datetime in the path\n",
    "        writer = SummaryWriter(os.path.join(\"logs\", \"MES\", f\"{formatted_datetime}_{run_name}_run{iteration}\"))\n",
    "    \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_f1 = 0\n",
    "        step_count = 0\n",
    "        best_epoch_was = 0\n",
    "        for epoch in range(num_fine_epochs): #training loop\n",
    "            pbar = tqdm(iter(train_loader))\n",
    "            classifier.train() # Set the model to training mode\n",
    "            running_loss = 0.0\n",
    "            for images, labels in pbar: #do one epoch\n",
    "                # Move data to device\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = classifier(images)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                pbar.set_postfix({'step loss': loss.item(), 'epoch': epoch}, refresh=False)\n",
    "                writer.add_scalar('Fine_tune_loss/train-step', loss.item(), global_step=step_count)\n",
    "                \n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                step_count += 1\n",
    "                # Update running loss\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            #### EPOCH EVAL\n",
    "            # Train loss \n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            writer.add_scalar('Fine_tune_loss/train-epoch', epoch_loss, global_step=step_count)\n",
    "            \n",
    "            # Val loss + f1\n",
    "            classifier.eval() # Set the model to evaluation mode\n",
    "            running_val_loss = 0.0\n",
    "            running_f1_score = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = classifier(images)\n",
    "                    val_loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # Calculate F1 score\n",
    "                    labels_list = labels.cpu().numpy().tolist()\n",
    "                    # Convert output scores to predicted class labels\n",
    "                    predicted_labels = torch.argmax(outputs, dim=1).cpu().numpy().tolist()\n",
    "                    val_f1 = f1_score(labels_list, predicted_labels, average='weighted')\n",
    "\n",
    "                    running_val_loss += val_loss.item() * images.size(0)\n",
    "                    running_f1_score += val_f1 * images.size(0)\n",
    "            \n",
    "            val_epoch_loss = running_val_loss / len(val_loader.dataset)\n",
    "            val_f1_score = running_f1_score / len(val_loader.dataset)\n",
    "            writer.add_scalar('Fine_tune_loss/val-epoch_loss', val_epoch_loss, global_step=step_count)\n",
    "            writer.add_scalar('Fine_tune_loss/val-epoch_f1', val_f1_score, global_step=step_count)\n",
    "\n",
    "            #### SAVING\n",
    "            #last\n",
    "            torch.save({\n",
    "                        'model_state_dict': classifier.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': loss.item(),\n",
    "                        }, f'C:\\\\Users\\\\alx\\\\Downloads\\\\mdl_ckpt\\\\mes_m-{mask_ratio}\\\\mes_last.pth')\n",
    "            \n",
    "            #best val_loss\n",
    "            if val_epoch_loss < best_val_loss:\n",
    "                best_epoch_was = epoch\n",
    "                best_val_loss = val_epoch_loss\n",
    "                torch.save({\n",
    "                        'model_state_dict': classifier.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': loss.item(),\n",
    "                        'best_epoch_was': best_epoch_was,\n",
    "                        }, f'C:\\\\Users\\\\alx\\\\Downloads\\\\mdl_ckpt\\\\mes_m-{mask_ratio}\\\\mes_best.pth')\n",
    "            \n",
    "            #best val_f1\n",
    "            if val_f1_score > best_val_f1:\n",
    "                best_f1_epoch_was = epoch\n",
    "                best_val_f1 = val_f1_score\n",
    "                torch.save({\n",
    "                        'model_state_dict': classifier.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': loss.item(),\n",
    "                        'best_epoch_was': best_f1_epoch_was,\n",
    "                        }, f'C:\\\\Users\\\\alx\\\\Downloads\\\\mdl_ckpt\\\\mes_m-{mask_ratio}\\\\mes_best_f1.pth')\n",
    "\n",
    "\n",
    "        print(f\"Fine-tuning complete. Best epoch was {best_epoch_was}\")\n",
    "    return test_loader, test_data, now, best_epoch_was, best_f1_epoch_was, classifier\n",
    "\n",
    "if three_shot == False and fine_tuning == True: #så må det jo være 1-shot\n",
    "    test_loader, test_data, now, best_epoch_was, best_f1_epoch_was = single_mes_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load fine tuned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_fine_tuned or three_shot:\n",
    "    def load_fine_tuned_model(path):\n",
    "        load_prev_fine_model_path = path\n",
    "        import torch\n",
    "        import os\n",
    "        # try:\n",
    "        #     step_count\n",
    "        # except NameError:\n",
    "        #     step_count = 190000 // batch_size * 64\n",
    "        # Load the checkpoint\n",
    "        checkpoint = torch.load(load_prev_fine_model_path)\n",
    "        encoder = MAE_Encoder(image_size=dim, mask_ratio=mask_ratio, emb_dim=emb_dims) #xxx\n",
    "        # Load the model state dict\n",
    "        classifier = ViT_Classifier(encoder).to(device)#\n",
    "        classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # Load the optimizer state dict\n",
    "        if custom_opt == \"prodigy\":\n",
    "            optimizer = Prodigy(classifier.parameters())\n",
    "        #optimizer.load_state_dict(checkpoint['optimizer_state_dict']) #do we need this?\n",
    "        elif custom_opt == \"adamW\":\n",
    "            optimizer = AdamW(classifier.parameters(), lr=learn_rate)\n",
    "        # Load the loss\n",
    "        loss = checkpoint['loss']\n",
    "        try:\n",
    "            best_epoch_was = checkpoint['best_epoch_was']\n",
    "        except KeyError:\n",
    "            best_epoch_was = num_fine_epochs\n",
    "        \n",
    "        \n",
    "        print(f\"Model loaded with loss: {loss}, where best/last epoch was {best_epoch_was}\")\n",
    "        return classifier, optimizer, loss, best_epoch_was\n",
    "    \n",
    "if not three_shot and load_fine_tuned:\n",
    "    classifier, optimizer, loss, best_epoch_was = load_fine_tuned_model(load_prev_fine_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval fine tuned calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune_eval == True or three_shot:    \n",
    "    def calculate_evaluation_metrics(classifier, test_data):\n",
    "        # from sklearn.metrics import classification_report\n",
    "        # from concurrent.futures import ThreadPoolExecutor\n",
    "        from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "        from tqdm import tqdm\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        def evaluate_single_sample(i):\n",
    "            # Get the sample from the dataset\n",
    "            sample, true_label = test_data[i]\n",
    "            \n",
    "            # Move the sample to the same device as the model\n",
    "            sample = sample.to(device)\n",
    "            \n",
    "            # Pass the sample through the model\n",
    "            with torch.no_grad():\n",
    "                prediction = classifier(sample.unsqueeze(0))  # Unsqueeze to add batch dimension\n",
    "\n",
    "            class_probabilities = prediction[0]\n",
    "\n",
    "\n",
    "            _, predicted_class = torch.max(class_probabilities, dim=0)\n",
    "\n",
    "            # Move the predicted_class back to CPU for further operations\n",
    "            predicted_class = predicted_class.to('cpu')\n",
    "            \n",
    "\n",
    "            \n",
    "            # Return the true label and the predicted class\n",
    "            return true_label.item(), predicted_class.item()\n",
    "\n",
    "        # Ensure the model is in evaluation mode\n",
    "        classifier.eval()\n",
    "\n",
    "        # Shared lists to store true labels and predicted classes\n",
    "        true_labels_list = []\n",
    "        predicted_classes_list = []\n",
    "\n",
    "        # Evaluate all samples sequentially\n",
    "        for i in tqdm(range(len(test_data)), desc='Evaluating'):\n",
    "            true_label, predicted_class = evaluate_single_sample(i)\n",
    "            true_labels_list.append(true_label)\n",
    "            predicted_classes_list.append(predicted_class)\n",
    "\n",
    "        # Assuming `true_labels` and `predicted_labels` are already defined\n",
    "        f1 = f1_score(true_labels_list, predicted_classes_list, average='weighted')\n",
    "        accuracy = accuracy_score(true_labels_list, predicted_classes_list)\n",
    "        precision = precision_score(true_labels_list, predicted_classes_list, average='weighted')\n",
    "        recall = recall_score(true_labels_list, predicted_classes_list, average='weighted')\n",
    "        cm = confusion_matrix(true_labels_list, predicted_classes_list)\n",
    "    \n",
    "        return f1, accuracy, precision, recall, cm\n",
    "\n",
    "# f1, accuracy, precision, recall, cm = calculate_evaluation_metrics(classifier, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Num params in clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_params = sum(p.numel() for p in classifier.parameters())\n",
    "# print(f\"Total number of parameters: {total_params:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval fine tune plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune_eval == True or three_shot:\n",
    "    def mes_run_eval_plot(f1, accuracy, precision, recall, cm, iteration, model_used, best_epoch_was, eval_plot_name):   \n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        def format_number(num):\n",
    "            if num >= 1000000:\n",
    "                return f\"{num // 1000000}M\"\n",
    "            elif num >= 1000:\n",
    "                return f\"{num // 1000}K\"\n",
    "            else:\n",
    "                return str(num)\n",
    "        \n",
    "        # Create a figure and a 2x1 grid of subplots\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "        # Confusion matrix subplot\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axs[0])\n",
    "        axs[0].set_title('Confusion Matrix')\n",
    "        axs[0].set_xlabel('Predicted')\n",
    "        axs[0].set_ylabel('True')\n",
    "\n",
    "        # F1 Score, Precision, Recall, and Accuracy subplot\n",
    "        num_train_samples = len(dataloader)*MAE_batch_size # MAE image count we are interested in here\n",
    "        num_train_samples = format_number(num_train_samples)\n",
    "        total_params = sum(p.numel() for p in classifier.parameters())\n",
    "        axs[1].set_title(f'{architecture}, run: {iteration + 1} \\n optimizer = {custom_opt}, MES-bs: {mes_batch_size}, \\n MES fine-tuned for: {num_fine_epochs}e, model has {total_params:,.0f} num params. \\n Best val loss was on epoch {best_epoch_was}')\n",
    "        axs[1].text(0.5, 0.8, f'F1 Score: {f1:.2f}', horizontalalignment='center', verticalalignment='center', fontsize=14)\n",
    "        axs[1].text(0.5, 0.4, f'Precision: {precision:.2f}', horizontalalignment='center', verticalalignment='center', fontsize=14)\n",
    "        axs[1].text(0.5, 0.2, f'Recall: {recall:.2f}', horizontalalignment='center', verticalalignment='center', fontsize=14)\n",
    "        axs[1].text(0.5, 0.6, f'Accuracy: {accuracy:.2f}', horizontalalignment='center', verticalalignment='center', fontsize=14)\n",
    "        axs[1].axis('off')\n",
    "        \n",
    "        fig.suptitle(f'MES evaluation', fontsize=20)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./plots/eval_plot-{architecture}-{iteration}.png')\n",
    "        plt.show()\n",
    "\n",
    "    # mes_run_eval_plot(f1, accuracy, precision, recall, cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO 3 MES runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### RUN 2/3 ###\n",
      "Original DataFrame size: 1738, Filtered DataFrame size: 1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:08<00:00,  3.66s/it, step loss=0.277, epoch=0]\n",
      "100%|██████████| 35/35 [02:09<00:00,  3.71s/it, step loss=0.0981, epoch=1]\n",
      "100%|██████████| 35/35 [02:07<00:00,  3.64s/it, step loss=0.0699, epoch=2]\n",
      "100%|██████████| 35/35 [02:07<00:00,  3.64s/it, step loss=0.00449, epoch=3]\n",
      "100%|██████████| 35/35 [02:08<00:00,  3.68s/it, step loss=0.17, epoch=4]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete. Best epoch was 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 348/348 [00:40<00:00,  8.63it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if three_shot:\n",
    "    #load MAE \n",
    "    from sklearn.metrics import f1_score\n",
    "    from IPython.display import clear_output\n",
    "    mes_load_dir =  f'C:\\\\Users\\\\alx\\\\Downloads\\\\mdl_ckpt\\mes_m-{mask_ratio}' #used for loading\n",
    "\n",
    "    for i in range(3): #3 MES runs\n",
    "        clear_output()\n",
    "        print(f'### RUN {i}/3 ###')\n",
    "\n",
    "        #run MES training:\n",
    "        test_loader, test_data, now, best_epoch_was, best_f1_epoch_was, classifier = single_mes_run(i)\n",
    "\n",
    "        # run eval on last model\n",
    "        # specific_model_path = 'mes_last.pth'\n",
    "        # specific_load_path = os.path.join(mes_load_dir, specific_model_path)\n",
    "        model_used = 'last'\n",
    "        eval_plot_name = f\"MAE-370K_opt-{custom_opt}_max-e-{num_epochs}_MAE_mes-bs-{MAE_batch_size}_{mes_batch_size}_mask-{mask_ratio}_embdims-{emb_dims}_fine-e-{num_fine_epochs}_last_run{i+1}\"\n",
    "        f1, accuracy, precision, recall, cm = calculate_evaluation_metrics(classifier, test_data)\n",
    "        mes_run_eval_plot(f1, accuracy, precision, recall, cm, i, model_used, best_epoch_was, eval_plot_name)\n",
    "\n",
    "        # # run eval on best  val loss model\n",
    "        # #load best.pth\n",
    "        # specific_model_path = 'mes_best.pth'\n",
    "        # specific_load_path = os.path.join(mes_load_dir, specific_model_path)\n",
    "        # load_fine_tuned_model(path=specific_load_path)\n",
    "        \n",
    "        # model_used = 'best_val_loss'\n",
    "        # eval_plot_name = f\"MAE-370K_opt-{custom_opt}_max-e-{num_epochs}_MAE_mes-bs-{MAE_batch_size}_{mes_batch_size}_mask-{mask_ratio}_embdims-{emb_dims}_fine-e-{num_fine_epochs}_best-valloss_run{i+1}\"\n",
    "        # f1, accuracy, precision, recall, cm = calculate_evaluation_metrics(classifier, test_data)\n",
    "        # mes_run_eval_plot(f1, accuracy, precision, recall, cm, i, model_used, best_epoch_was, eval_plot_name)\n",
    "\n",
    "\n",
    "        # # run eval on best f1 score\n",
    "        # #load best_f1.pth\n",
    "        # specific_model_path = 'mes_best_f1.pth'\n",
    "        # specific_load_path_f1 = os.path.join(mes_load_dir, specific_model_path)\n",
    "        # load_fine_tuned_model(path=specific_load_path_f1)\n",
    "\n",
    "        # model_used = 'best_val_f1'\n",
    "        # eval_plot_name = f\"MAE-370K_opt-{custom_opt}_max-e-{num_epochs}_MAE_mes-bs-{MAE_batch_size}_{mes_batch_size}_mask-{mask_ratio}_embdims-{emb_dims}_fine-e-{num_fine_epochs}_best-val-f1_run{i+1}\"\n",
    "        # f1, accuracy, precision, recall, cm = calculate_evaluation_metrics(classifier, test_data)\n",
    "        # mes_run_eval_plot(f1, accuracy, precision, recall, cm, i, model_used, best_epoch_was, eval_plot_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime of this run: 0.0 hrs\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total runtime of this run: {total_time//60//60} hrs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    import winsound\n",
    "\n",
    "    # Play a sound\n",
    "    winsound.PlaySound(\"SystemExit\", winsound.SND_ALIAS)\n",
    "    winsound.PlaySound(\"SystemExit\", winsound.SND_ALIAS)\n",
    "    winsound.PlaySound(\"SystemExit\", winsound.SND_ALIAS)\n",
    "    winsound.PlaySound(\"SystemExit\", winsound.SND_ALIAS)\n",
    "    winsound.PlaySound(\"SystemExit\", winsound.SND_ALIAS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
