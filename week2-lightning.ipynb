{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # circular import?\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prodigyopt import Prodigy\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "import lightning as L\n",
    "from torchmetrics import F1Score\n",
    "import wandb\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "single_shot = False\n",
    "learning_rate = 0.001  # Doesn't matter when using prodigy optimizer\n",
    "use_prodigy = True\n",
    "epochs = 15  # Max_limit\n",
    "batch_size = 32\n",
    "architecture = \"vit_base_patch16_224\"\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'week2-lightning.ipynb'\n",
    "use_class4 = False\n",
    "\n",
    "run_name = f'epochs-{epochs}_bs-{batch_size}_class4-{use_class4}_{architecture}'\n",
    "\n",
    "if use_prodigy:\n",
    "    optimizer = \"Prodigy\"\n",
    "else:\n",
    "    optimizer = \"Adam\"\n",
    "    learning_rate = \"Prodigy\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes,\n",
    "        learning_rate=learning_rate,\n",
    "        use_prodigy=use_prodigy,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\n",
    "            architecture, pretrained=True, num_classes=num_classes\n",
    "        )  # Get model architecture\n",
    "        self.f1 = F1Score(task=\"multiclass\", num_classes=num_classes, average=\"macro\")\n",
    "        self.save_hyperparameters()\n",
    "        self.predictions = []\n",
    "        self.labels = []\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if use_prodigy:\n",
    "            return Prodigy(self.model.parameters())\n",
    "        else:\n",
    "            return torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_hat, y)\n",
    "        val_f1 = self.f1(y_hat, y)\n",
    "        \n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        val_accuracy = (preds == y).float().mean()\n",
    "\n",
    "        self.log_dict(\n",
    "            {\"val_loss\": loss, \"val_f1\": val_f1, \"val_accuracy\": val_accuracy},\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        # Store preds and labels for later use in on_test_epoch_end\n",
    "        self.predictions.append(preds)\n",
    "        self.labels.append(y)\n",
    "        # Optionally compute and return the loss if you want to log it\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.log('test_loss', loss)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # Concatenate all the predictions and labels collected from each test_step\n",
    "        preds = torch.cat(self.predictions, dim=0)\n",
    "        labels = torch.cat(self.labels, dim=0)\n",
    "        # Convert to CPU numpy arrays for sklearn\n",
    "        preds = preds.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        # Reset predictions and labels list to avoid duplicate entries on multiple test runs\n",
    "        self.predictions = []\n",
    "        self.labels = []\n",
    "        #Log accuracy and f1 to wandb\n",
    "        \n",
    "        # Log the confusion matrix to wandb\n",
    "        wandb.log({\"confusion_matrix\": wandb.plot.confusion_matrix(probs=None, y_true=labels, preds=preds)})\n",
    "\n",
    "\n",
    "if use_class4 == True:\n",
    "    vit = ViTModel(num_classes=5, use_prodigy=use_prodigy)\n",
    "else:\n",
    "    vit = ViTModel(num_classes=4, use_prodigy=use_prodigy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx, 0]\n",
    "        img_path = f'img/{img_name}'\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = torch.tensor(self.df.iloc[idx, 2], dtype=torch.long)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    def get_labels(self):\n",
    "        label = torch.tensor(self.df.iloc[:, 2].tolist(), dtype=torch.long)\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame size: 1738, Filtered DataFrame size: 1735\n"
     ]
    }
   ],
   "source": [
    "#DATA LABELS\n",
    "df = pd.read_csv('img_labels_ALL.csv')\n",
    "\n",
    "# Remove class 4 (images lablelled as bad examples)?\n",
    "if use_class4 == False:\n",
    "    df = df[df['score'] != 4.0]\n",
    "#df.head() #Sanity check\n",
    "\n",
    "# Only use images that exist in the directory\n",
    "image_folder = 'img'  \n",
    "image_exists = df['img'].apply(lambda x: os.path.isfile(os.path.join(image_folder, x)))\n",
    "filtered_df = df[image_exists]\n",
    "print(f\"Original DataFrame size: {len(df)}, Filtered DataFrame size: {len(filtered_df)}\") #Sanity check\n",
    "df = filtered_df\n",
    "\n",
    "# Stratify/balance classes across splits\n",
    "labels = df['score'].values\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=labels)\n",
    "train_labels = train_df['score'].values\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_labels)\n",
    "\n",
    "# Create a transform for the images\n",
    "transform = timm.data.create_transform(\n",
    "     **timm.data.resolve_data_config(vit.model.pretrained_cfg))\n",
    "\n",
    "# Create data loaders for training and validation sets\n",
    "test_data = CustomDataset(test_df, transform)\n",
    "train_data = CustomDataset(train_df, transform)\n",
    "val_data = CustomDataset(val_df, transform)\n",
    "\n",
    "#More workers for GPU/lambda\n",
    "if torch.cuda.is_available():\n",
    "    num_workers_local = 13\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=num_workers_local)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, sampler=ImbalancedDatasetSampler(train_data), num_workers=num_workers_local)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, num_workers=num_workers_local)\n",
    "else:\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, sampler=ImbalancedDatasetSampler(train_data))\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda list --export > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "wandb_logger = WandbLogger(project=\"BA1\", name=run_name)\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=epochs,\n",
    "    log_every_n_steps=1,\n",
    "    logger=wandb_logger,\n",
    ")\n",
    "#default_root_dir=\"./models\", #if starting from prev checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandermittet\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240227_132443-ld5tt1ru</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alexandermittet/BA1/runs/ld5tt1ru' target=\"_blank\">epochs-15_bs-64_class-False_vit_base_patch16_224</a></strong> to <a href='https://wandb.ai/alexandermittet/BA1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alexandermittet/BA1' target=\"_blank\">https://wandb.ai/alexandermittet/BA1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alexandermittet/BA1/runs/ld5tt1ru' target=\"_blank\">https://wandb.ai/alexandermittet/BA1/runs/ld5tt1ru</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    }
   ],
   "source": [
    "wandb_logger.watch(vit)\n",
    "# Dynamically update W&B configuration\n",
    "wandb.config.update({\n",
    "    \"single_shot\": single_shot,\n",
    "    \"max_epochs\": epochs,\n",
    "    \"batch_size\": batch_size,  # Assuming this is how you access batch size\n",
    "    \"learning_rate\": learning_rate,  # Dynamically get the learning rate from optimizer\n",
    "    \"optimizer\": optimizer,  # Dynamically get the optimizer class name\n",
    "    \"model_architecture\": architecture,\n",
    "    'use_class4': use_class4,\n",
    "    # Include any other dynamic parameters here\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | VisionTransformer | 85.8 M\n",
      "1 | f1    | MulticlassF1Score | 0     \n",
      "--------------------------------------------\n",
      "85.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "85.8 M    Total params\n",
      "343.207   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df868d8beb844f969bd9436d1a360f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandermittet/miniconda3/envs/BA/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/alexandermittet/miniconda3/envs/BA/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d1dce5fd3543eb94c4a8b8e80e9699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e15ed56221543588752f42e5a735d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c4cefd15ca44589be436f4130b6870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377d5d1d89554e6780926eab1155473c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandermittet/miniconda3/envs/BA/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(vit, train_loader, val_loader)\n",
    "\n",
    "# automatically restores model, epoch, step, LR schedulers, etc...\n",
    "#trainer.fit(vit, train_loader, val_loader, ckpt_path=\"BA1/n9o5487v/checkpoints/epoch=0-step=26.ckpt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parallel evaluations of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandermittet/miniconda3/envs/BA/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c98318e5704bfcb58f06c0b0b46fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_0': {'precision': 0.9248554913294798, 'recall': 0.975609756097561, 'f1-score': 0.9495548961424333, 'support': 164.0}, 'class_1': {'precision': 0.8656716417910447, 'recall': 0.6444444444444445, 'f1-score': 0.7388535031847133, 'support': 90.0}, 'class_2': {'precision': 0.6705882352941176, 'recall': 0.8142857142857143, 'f1-score': 0.7354838709677419, 'support': 70.0}, 'class_3': {'precision': 0.6363636363636364, 'recall': 0.6086956521739131, 'f1-score': 0.6222222222222222, 'support': 23.0}, 'accuracy': 0.8328530259365994, 'macro avg': {'precision': 0.7743697511945695, 'recall': 0.7607588917504082, 'f1-score': 0.7615286231292777, 'support': 347.0}, 'weighted avg': {'precision': 0.8390901684327969, 'recall': 0.8328530259365994, 'f1-score': 0.8300253611897301, 'support': 347.0}}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4893971085548401\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "report = trainer.test(vit, test_loader)\n",
    "# print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Format the date and time as a string\n",
    "timestamp = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Include the timestamp in the filename\n",
    "torch.save(vit.state_dict(), f\"models/{run_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip freeze > pip_requirements.txt\n",
    "\n",
    "# pip freeze | grep -v ' @ ' > pip_requirements.txt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
